---
title: Scraping the MMWR with rvest
author: Monica Gerber
date: '2018-03-18'
slug: scraping-the-mmwr-with-rvest
categories:
  - webscraping
  - public health
tags:
  - mmwr rvest
draft: true
---

## rvest in action

First, we need to create a html document from the URL of the page we want using `read_html()`.

```{r eval=FALSE}

library(rvest)
cdc_site <- read_html("http://www.cdc.gov/mmwr/volumes/65/wr/mm6545a2.htm?s_cid=mm6545a2_w")
```

After we have the html document, we need to select part of the document using CSS selectors. I read up on selectorgadget (see `r vignette("selectorgadget")`) to help me figure out which selector to use. However, for this task, I found it easier to just extract the type of element we want, which is the table.

We can use `html_node()` to extract the table in the html document. Then, we use `html_table()` to parse the html table into a data frame. Note that if there were more than 1 table, we could use `html_nodes()`, and then select which table we want with either `magrittr::extract2()` or `[[`. We set `fill = TRUE` because the columns in the the top row are merged and contain headings.

```{r eval=FALSE}
library(magrittr)
wic_table <- cdc_site %>%
  html_node("table")  %>% 
  html_table(fill = TRUE)
```

That's pretty cool that we can get the data into a data frame in just a few lines of code!

## clean up 

We've successfully scrapped the data, but now our problem is that the data frame consists of character varibles because there were 3 rows of column headers:

```{r eval=FALSE}
str(wic_table)
```

First I'll rename everything using `set_names()` from magrittr. And then I'll clean this up using functions from dplyr and tidyr from the tidyverse.

```{r eval=FALSE}
library(tidyverse)

tidy_wic <- wic_table %>%
  set_names(c("state",
              "n_2000",
               "n_2004",
               "n_2010",
               "n_2014",
               "obesity_2000",
               "obesity_2004",
               "obesity_2010",
               "obesity_2014",
               "dif_2004",
               "dif_2010",
               "dif_2014")) %>%
  filter(row_number() > 2,
         state != "Territory") %>%
  gather(key, measure, -state) %>%
  separate(key, into = c("stat", "year"), sep = "_") %>%
  spread(key = stat, value = measure) %>%
  separate(dif, into = c("dif", "ci"), sep = " ", extra = "merge") %>%
  separate(ci, into = c("lower_ci", "upper_ci"), sep = " to ") %>%
  mutate_at(vars(n, dif, lower_ci, upper_ci, obesity), parse_number) %>%
  as_tibble() 
```

Ta-da! It's now in a much more usable format!

## visualize

Now that it's in a tidy format, we can create our own data visualizations.

[geofacet](https://hafen.github.io/geofacet/)

[plotly](https://talks.cpsievert.me/20180202/#23)


```{r eval=FALSE}
library(leaflet)
library(sp)
library(geojson)
library(geojsonio)
url <- "http://leafletjs.com/examples/choropleth/us-states.js"

# read as text file
doc <- readLines(url)

# remove the javascript assignment at the front 
doc2 <- gsub("var statesData = ", "", doc)

# write out as a temp file and read
write(doc2, file = "tempgeo.json")
states <- geojson_read("tempgeo.json", what = "sp")

# ^ found out how to get this data into R thanks to this stack overflow post! 
# https://stackoverflow.com/questions/43443260/how-to-download-geojson-data-and-read-it-to-r

# merge data
# first filter out non-states

wic_states <- tidy_wic %>%
  filter(!state %in% c("DC", "OverallÂ¶", "Northern Mariana Islands",
                       "Puerto Rico", "Virgin Islands", "Guam",
                       "American Samoa")) %>%
  filter(year == "2014")

wic_sp <- merge(states, wic_states, 
                by.x = "name", by.y = "state",
                duplicateGeoms = TRUE)

bins <- c(7, 12.66, 13.52, 14.78, 16.3, 20)
pal <- colorBin("YlOrRd", domain = wic_sp$obesity, bins = bins)

labels <- sprintf(
  "<strong>%s</strong>",
  wic_sp$obesity
) %>% lapply(htmltools::HTML)

wic_sp %>%
  leaflet() %>%
  setView(-96, 37.8, 4) %>%
  addTiles() %>%
  addPolygons(
  fillColor = ~pal(obesity),
  weight = 2,
  opacity = 1,
  color = "white",
  dashArray = "3",
  fillOpacity = 0.7)

wic_states %>% 
  summarise(`20%`=quantile(obesity, probs=0.20),
            `40%`=quantile(obesity, probs=0.4),
            `60%`=quantile(obesity, probs=0.60),
            `80%`=quantile(obesity, probs=0.80))


```


```{r eval=FALSE}
html_doc <- read_html("https://www.cdc.gov/mmwr/volumes/67/wr/mm6706a3.htm?s_cid=mm6706a3_w")

obesity_table <- html_doc %>%
  html_node("table")  %>% 
  html_table(fill = TRUE)

```


```{r eval=FALSE}
library(rvest)
library(tidyverse)

mmwr_site <- read_html("https://www.cdc.gov/mmwr/mmwr_wk/wk_pvol.html")

css <- paste0(paste0("#anch_", 13:47), collapse=", ")

issues <- mmwr_site %>%
  html_nodes(css = css) %>%
  html_attr("href")

issues[1:3] <- paste0("https://www.cdc.gov", issues[1:3])


test <- read_html(issues[1]) %>%
  html_nodes(css = "ul:nth-child(10) li") 



```


```{r eval=FALSE}
library(RISmed)

myquery <- "MMWR. Morbidity and mortality weekly report[Journal]"

search_query <- EUtilsSummary(myquery, 
                              type = "esearch",
                              db = "pubmed")
summary(search_query)

records <- EUtilsGet(search_query)

pubmed_data <- data.frame('title' = ArticleTitle(records),
                      'abstract' = AbstractText(records))

```




